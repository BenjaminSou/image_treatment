{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "from keras.preprocessing import image\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pretrained model with our patched version of layers \n",
    "model = MobileNetV2(layers=layers, weights=None, include_top=True , classes=3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 150/1000\n",
    "#224/224 [==============================] - 287s 1s/step - loss: 0.0187 - acc: 0.9934 - val_loss: 0.4063 - val_acc: 0.9348\n",
    "\n",
    "#load weights\n",
    "model.load_weights(\"MobileNet_5.weights.150-0.41.my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "\n",
    "#Paths\n",
    "train_path = 'Data/Train'\n",
    "validation_path = 'Data/Validation'\n",
    "test_path = 'Data/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x.astype(np.float32))\n",
    "    return x\n",
    "\n",
    "def preprocess2(x):\n",
    "    return preprocess(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myIterator(path):\n",
    "    l = []\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    filesWithDir = [os.path.join(path, file) for file in files]\n",
    "    #while True:\n",
    "   \n",
    "    for i, elt in enumerate(filesWithDir):\n",
    "        # Open the file\n",
    "        img = plt.imread(elt)\n",
    "        #print('Le nom de l image : ' , name_of_image)\n",
    "        #  le redimensionner\n",
    "        matrix = resize(img,(height, width,3)) * 255\n",
    "        t = (matrix, img , elt)\n",
    "        l.append(t)\n",
    "        \n",
    "    return l \n",
    "\n",
    "#print(len(list(iterator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],  optimizer = 'Adam')\n",
    "image_gen2 = ImageDataGenerator(preprocessing_function = preprocess2)\n",
    "batch_size_valid = 32\n",
    "def countfiles(path):\n",
    "    return sum([len(files) for r,d, files in os.walk(path)])\n",
    "\n",
    "\n",
    "valid_size = countfiles(validation_path)\n",
    "\n",
    "validation_batches = image_gen2.flow_from_directory(validation_path ,\n",
    "                                            target_size=(height, width) ,\n",
    "                                            classes =['Neige' , 'Non_Neige' ,'indetermine'] ,\n",
    "                                            batch_size = batch_size_valid)\n",
    "\n",
    "print(model.evaluate_generator(validation_batches, steps=valid_size//32))\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting the first 10 images of a test batch \n",
    "imgs_val , labels_val = next(validation_batches)\n",
    "plt.imshow(imgs_val[4])\n",
    "print('img_val mean' , imgs_val[4].mean())\n",
    "print('img_val max' , imgs_val[4].max())\n",
    "print('img_val max' , imgs_val[4].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MyIterator of snowy images\n",
    "data_validation_snowy_images =  myIterator(validation_path+ '/Neige')\n",
    "label_validation_snowy_images = np.array([1. , 0. , 0.])\n",
    "\n",
    "#MyIterator of not snowy images\n",
    "data_validation_not_snowy_images =  myIterator(validation_path+ '/Non_Neige')\n",
    "label_validation_not_snowy_images = np.array([0. , 1. , 0.])\n",
    "\n",
    "#MyIterator of undetermined images \n",
    "data_validation_undetermined_images =  myIterator(validation_path+ '/indetermine')\n",
    "label_validation_undetermined_images = np.array([0. , 0. , 1.])\n",
    "\n",
    "#Put all the predictions in one list\n",
    "predictions = []\n",
    "#trois dossiers\n",
    "for i in range(3):\n",
    "    if (i == 0):\n",
    "        true_label = label_validation_snowy_images\n",
    "        true_data = data_validation_snowy_images\n",
    "    elif(i == 1):\n",
    "        true_label = label_validation_not_snowy_images\n",
    "        true_data = data_validation_not_snowy_images  \n",
    "    else:\n",
    "        true_label = label_validation_undetermined_images\n",
    "        true_data = data_validation_undetermined_images\n",
    "   # tuple_data = (np matrix resized, img , nom_image)\n",
    "    for tuple_data in true_data:\n",
    "        data = tuple_data[0]\n",
    "        #print(data.dtype)\n",
    "        #print('Min: %.3f, Max: %.3f' % (data.min(), data.max()))\n",
    "        data_exp = preprocess(data)\n",
    "        #print(data_exp.dtype)\n",
    "        #print('Min: %.3f, Max: %.3f' % (data_exp.min(), data_exp.max()))\n",
    "        prediction = model.predict(data_exp)\n",
    "        pred_label = prediction[0]\n",
    "        #for each image return true_label , pred_label , the image and the name of the image\n",
    "        elt = true_label , pred_label , tuple_data[1] , tuple_data[2] , tuple_data[0]\n",
    "        predictions.append(elt)\n",
    "\n",
    "#print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print out the images that were well predicted\n",
    "print(\"Images prédites avec certitude\")\n",
    "count = 0\n",
    "for elt in predictions:\n",
    "    true_label , pred_label , image , name_of_image , img = elt\n",
    "    for i in range(3):\n",
    "        if (true_label[i] ==1.):\n",
    "            if (pred_label[i] >= 0.5):\n",
    "                print(true_label)\n",
    "                print(pred_label)\n",
    "                print('Le nom de l image : ' , name_of_image)\n",
    "                plt.imshow(image)\n",
    "                plt.show()\n",
    "                count += 1\n",
    "                break\n",
    "print('count = ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images prédites avec incertitude\")\n",
    "count = 0\n",
    "for elt in predictions:\n",
    "    true_label , pred_label , image , name_of_image , img = elt\n",
    "    for i in range(3):\n",
    "        if (true_label[i] ==1.):\n",
    "            if ((all(pred_label[i] >= a for a in pred_label)) and (pred_label[i] < 0.5)) :\n",
    "                print(true_label)\n",
    "                print(pred_label)\n",
    "                print('Le nom de l image : ' , name_of_image)\n",
    "                plt.imshow(image)\n",
    "                plt.show()\n",
    "                count += 1\n",
    "                break\n",
    "                \n",
    "print('count = ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print out the images that were not well predicted\n",
    "print(\"Images mal prédites\")\n",
    "count = 0\n",
    "\n",
    "for elt in predictions:\n",
    "    true_label , pred_label , image , name_of_image , img  = elt\n",
    "    \n",
    "    pred_class = np.argmax(pred_label)\n",
    "    true_class = np.argmax(true_label)\n",
    "    \n",
    "    if pred_class != true_class:\n",
    "        print(true_label)\n",
    "        print(pred_label)\n",
    "        print('Le nom de l image : ' , name_of_image)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        count += 1\n",
    "\n",
    "print('count = ' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "print('classify all of the images in the dataset')\n",
    "#classify all of the images in the dataset\n",
    "DataSet_path = 'DataSet/Images'\n",
    "\n",
    "#All files in the data set\n",
    "files = [f for f in os.listdir(DataSet_path) if os.path.isfile(os.path.join(DataSet_path, f))]\n",
    "filesWithDir = [os.path.join(DataSet_path, file) for file in files]\n",
    "\n",
    "#Transform each file into a numpy array in order to classify it\n",
    "for elt in filesWithDir:\n",
    "        # Open the file\n",
    "        img = plt.imread(elt)\n",
    "        matrix = resize(img,(height, width,3)) * 255\n",
    "        #process the data \n",
    "        data_exp = preprocess(matrix)\n",
    "        prediction = model.predict(data_exp)\n",
    "        pred_label = prediction[0]\n",
    "        #get the name of the file\n",
    "        words = elt.split('/')\n",
    "        FileName = words[-1]\n",
    "        #Move the file to the right directory  \n",
    "        if (all(pred_label[0] >= a for a in pred_label)):\n",
    "            destination = 'DataSet/Decision_Neige/'+FileName\n",
    "            shutil.move(elt, destination)\n",
    "            \n",
    "        elif(all(pred_label[1] >= a for a in pred_label)):\n",
    "            destination = 'DataSet/Decison_Non_Neige/'+FileName\n",
    "            shutil.move(elt, destination)\n",
    "            \n",
    "        else:\n",
    "            destination = 'DataSet/Decision_None/'+FileName\n",
    "            shutil.move(elt, destination)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
